{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Bayesian Optimization: practical edition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def get_free_gpu():\n",
    "    from pynvml import nvmlInit, nvmlDeviceGetHandleByIndex, nvmlDeviceGetMemoryInfo, nvmlDeviceGetCount\n",
    "    nvmlInit()\n",
    "\n",
    "    return np.argmax([\n",
    "        nvmlDeviceGetMemoryInfo(nvmlDeviceGetHandleByIndex(i)).free\n",
    "        for i in range(nvmlDeviceGetCount())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    cuda_id = get_free_gpu()\n",
    "    DEVICE = 'cuda:%d' % (get_free_gpu(), )\n",
    "    print('Selected %s' % (DEVICE, ))\n",
    "else:\n",
    "    DEVICE = 'cpu'\n",
    "    print('WARNING: using cpu!')\n",
    "\n",
    "### please, don't remove the following line\n",
    "x = torch.tensor([1], dtype=torch.float32).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## imports\n",
    "\n",
    "In this notebook, we are going to use `pyro`, however, there are multiple alternatives:\n",
    "- [`scikit-optimize`](https://pypi.org/project/scikit-optimize/)\n",
    "- [`gpytorch`](https://gpytorch.ai/)\n",
    "- [`sklearn`](https://scikit-learn.org/stable/modules/gaussian_process.html)\n",
    "- [`tfp`](https://www.tensorflow.org/probability/examples/Gaussian_Process_Latent_Variable_Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import pyro\n",
    "pyro.set_rng_seed(111222333)\n",
    "\n",
    "from pyro.contrib.gp.models import GPRegression\n",
    "from pyro.contrib.gp.kernels import RBF, Matern32, Matern52, Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def simple_objective(x):\n",
    "    return np.exp(-2 * x + 1) + np.exp(x) - 2.5\n",
    "\n",
    "X = np.array([0.1, 0.4, 0.9])\n",
    "y = simple_objective(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "xs = np.linspace(0, 1, num=100)\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.plot(xs, simple_objective(xs), color=plt.cm.tab10(1), lw=3)\n",
    "plt.scatter(X, y, s=100, color=plt.cm.tab10(3), zorder=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def plot_gp(gp, X=None, y=None, objective=None):\n",
    "    with torch.no_grad():\n",
    "        xs = torch.linspace(0, 1, 100, device=DEVICE, dtype=torch.float32)\n",
    "        mean, cov =  gp(xs.view(-1, 1), full_cov=True, noiseless=False)\n",
    "        std = torch.sqrt(cov.diag())\n",
    "\n",
    "    xs_ = xs.cpu().numpy()\n",
    "    mean_ = mean.cpu().numpy()\n",
    "    std_ = std.cpu().numpy()\n",
    "    \n",
    "    if X is not None and y is not None:\n",
    "        plt.scatter(X, y, color=plt.cm.tab10(0), s=100)\n",
    "    \n",
    "    if objective is not None:\n",
    "        plt.plot(xs_, objective(xs_), '--', color='black')\n",
    "    \n",
    "    plt.plot(xs_, mean_, lw=2)\n",
    "    plt.fill_between(\n",
    "        xs_, mean_ - std_, mean_ + std_,\n",
    "        alpha=0.2,\n",
    "        color=plt.cm.tab10(0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "pyro.clear_param_store()\n",
    "gp = GPRegression(\n",
    "    torch.tensor(X.reshape(-1, 1), dtype=torch.float32, device=DEVICE),\n",
    "    torch.tensor(y.reshape(-1), dtype=torch.float32, device=DEVICE),\n",
    "\n",
    "    noise=torch.tensor(1e-2),\n",
    "    kernel=RBF(\n",
    "        input_dim=1,\n",
    "        variance=torch.tensor(1, dtype=torch.float32, device=DEVICE),\n",
    "        lengthscale=torch.tensor(0.25, dtype=torch.float32, device=DEVICE)\n",
    "    ),\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "plot_gp(gp, X, y, objective=simple_objective)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Multi-start\n",
    "\n",
    "An aquisition can easily have multiple minima. At the same time grid and random searches are inefficient even\n",
    "for a cheap surrogate as GP (trained on a few point). Typically, multi-start algorithm is employed - several instances of gradient descent start from a randomly drawn locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def minimize_acq(x0, gp, acq, lr=1e-1, n_iters=128, progress_bar=lambda x: x):\n",
    "    x = torch.tensor(x0, dtype=torch.float32, device=DEVICE, requires_grad=True)\n",
    "    \n",
    "    ### not stochastic in this case\n",
    "    opt = torch.optim.SGD(lr=lr, params=[x])\n",
    "    \n",
    "    for _ in progress_bar(range(n_iters)):\n",
    "        opt.zero_grad()        \n",
    "        torch.sum(acq(gp, x)).backward()\n",
    "        opt.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            x = torch.clamp(x, 0, 1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        values = acq(gp, x)\n",
    "\n",
    "    return x.detach().cpu().numpy(), values.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Lower confidence bound\n",
    "\n",
    "Simple, yet effective: $$\\mathrm{LCB}(x) = \\mu(x) - \\alpha\\cdot\\sigma(x)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def lcb(gp, x, alpha=1.0):\n",
    "    mean, cov = gp(x, full_cov=True, noiseless=False)\n",
    "    std = torch.sqrt(cov.diag())\n",
    "    \n",
    "    return mean - alpha * std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "### checking if multi-start properly optimizes aquisition function\n",
    "x0 = np.random.uniform(0, 1, size=25).reshape(-1, 1)\n",
    "with torch.no_grad():\n",
    "    v0 = lcb(\n",
    "        gp, torch.tensor(\n",
    "            x0, dtype=torch.float32,\n",
    "            device=DEVICE, requires_grad=False\n",
    "        )\n",
    "    ).detach().cpu().numpy()\n",
    "\n",
    "x, v = minimize_acq(\n",
    "    x0 = x0,\n",
    "    gp=gp,\n",
    "    acq=lcb,\n",
    "    n_iters=128,\n",
    "    progress_bar=tqdm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "plot_gp(gp, X, y)\n",
    "plt.scatter(x0[:, 0], v0, color=plt.cm.tab10(0), alpha=0.5, label='initial')\n",
    "plt.scatter(x[:, 0], v, color=plt.cm.tab10(1), label='optimized')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "class BayesianOptimization(object):\n",
    "    def __init__(self, gp_model, acq, lr=1e-1, ndim=1, n_multi_start=32, warmup=2):\n",
    "        self.gp_model = gp_model\n",
    "        self.gp = None\n",
    "\n",
    "        self.acq = acq\n",
    "        self.ndim = ndim\n",
    "        self.n_multi_start = n_multi_start\n",
    "        self.warmup = warmup\n",
    "        \n",
    "        self.X = list()\n",
    "        self.y = list()\n",
    "    \n",
    "    def reset(self, ):\n",
    "        self.X = list()\n",
    "        self.y = list()\n",
    "        self.gp = None\n",
    "    \n",
    "    def ask(self):\n",
    "        if len(self.X) < self.warmup:\n",
    "            return np.random.uniform(0, 1, size=self.ndim)\n",
    "        \n",
    "        ### optimizing aquisition function\n",
    "        suggestions, values = minimize_acq(\n",
    "            x0=np.random.uniform(0, 1, size=(self.n_multi_start, self.ndim)),\n",
    "            gp=self.gp,\n",
    "            acq=self.acq\n",
    "        )\n",
    "\n",
    "        ### returning the best guess\n",
    "        best = np.argmin(values)\n",
    "        return suggestions[best]\n",
    "    \n",
    "    def tell(self, x, y):\n",
    "        self.X.append(x)\n",
    "        self.y.append(y)\n",
    "        \n",
    "        X = torch.tensor(self.X, dtype=torch.float32, device=DEVICE).view(-1, self.ndim)\n",
    "        y = torch.tensor(self.y, dtype=torch.float32, device=DEVICE).view(-1,)\n",
    "        \n",
    "        ### 'retraining' model\n",
    "        pyro.clear_param_store()\n",
    "        self.gp = self.gp_model(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "bo = BayesianOptimization(\n",
    "    gp_model=lambda X, y: GPRegression(\n",
    "        X, y,\n",
    "        noise=torch.tensor(1e-4),\n",
    "        kernel=RBF(\n",
    "            input_dim=1,\n",
    "            variance=torch.tensor(1, dtype=torch.float32, device=DEVICE),\n",
    "            lengthscale=torch.tensor(2e-1, dtype=torch.float32, device=DEVICE)\n",
    "        ),\n",
    "    ).to(DEVICE),\n",
    "    \n",
    "    acq=lcb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "bo.reset()\n",
    "\n",
    "for _ in range(5):\n",
    "    x = bo.ask()\n",
    "    y = simple_objective(x)\n",
    "    \n",
    "    bo.tell(x, y)\n",
    "    \n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plot_gp(bo.gp, X=np.array(bo.X), y=np.array(bo.y), objective=simple_objective)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## More challenge!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def objective_2_minima(x):\n",
    "    return 0.75 * np.sin(-12 * x + 1) * np.cos(x) + 0.5 * np.exp(x) - 0.5\n",
    "\n",
    "xs = np.linspace(0, 1, num=100)\n",
    "plt.plot(xs, objective_2_minima(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "bo = BayesianOptimization(\n",
    "    gp_model=lambda X, y: GPRegression(\n",
    "        X, y,\n",
    "        noise=torch.tensor(1e-4),\n",
    "        ### switched to Matern kernel\n",
    "        kernel=Matern32(\n",
    "            input_dim=1,\n",
    "            variance=torch.tensor(1, dtype=torch.float32, device=DEVICE),\n",
    "            lengthscale=torch.tensor(0.25, dtype=torch.float32, device=DEVICE)\n",
    "        ),\n",
    "    ).to(DEVICE),\n",
    "    acq=lcb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "bo.reset()\n",
    "\n",
    "for _ in range(10):\n",
    "    x = bo.ask()\n",
    "    y = objective_2_minima(x)\n",
    "    \n",
    "    bo.tell(x, y)\n",
    "    \n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plot_gp(bo.gp, X=np.array(bo.X), y=np.array(bo.y), objective=objective_2_minima)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Take it to the limit\n",
    "\n",
    "Let's see if GP can approximate a complex function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "### Purely explorative acquisition function.\n",
    "def exlorative(gp, x, alpha=1.0):\n",
    "    mean, cov = gp(x, full_cov=True, noiseless=False)\n",
    "    std = torch.sqrt(cov.diag())\n",
    "    \n",
    "    return - std\n",
    "\n",
    "### Purely exploitative acquisition function.\n",
    "def exploitative(gp, x, alpha=1.0):\n",
    "    mean, cov = gp(x, full_cov=True, noiseless=False)\n",
    "    std = torch.sqrt(cov.diag())\n",
    "    \n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "m = 20\n",
    "w = np.random.uniform(-1, 1, size=m)\n",
    "periods = np.arange(1, m + 1) * np.pi\n",
    "\n",
    "def objective_many_minima_much_challenge(x):\n",
    "    return np.sum(\n",
    "        w[:, None] * np.cos(x[None, :] * periods[:, None]),\n",
    "        axis=0\n",
    "    ) + x ** 2\n",
    "\n",
    "xs = np.linspace(0, 1, num=100)\n",
    "plt.plot(xs, objective_many_minima_much_challenge(xs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Approximation check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "bo = BayesianOptimization(\n",
    "    gp_model=lambda X, y: GPRegression(\n",
    "        X, y,\n",
    "        noise=torch.tensor(1e-4),\n",
    "        ### switched to Matern kernel\n",
    "        kernel=Matern32(\n",
    "            input_dim=1,\n",
    "            variance=torch.tensor(1, dtype=torch.float32, device=DEVICE),\n",
    "            lengthscale=torch.tensor(0.1, dtype=torch.float32, device=DEVICE)\n",
    "        ),\n",
    "    ).to(DEVICE),\n",
    "    acq=exlorative\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "bo.reset()\n",
    "\n",
    "for i in range(20):\n",
    "    x = bo.ask()\n",
    "    y = objective_many_minima_much_challenge(x)\n",
    "    \n",
    "    bo.tell(x, y)\n",
    "    \n",
    "    if (i + 1) % 5 == 0:\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plot_gp(bo.gp, X=np.array(bo.X), y=np.array(bo.y), objective=objective_many_minima_much_challenge)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Optimization check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "bo = BayesianOptimization(\n",
    "    gp_model=lambda X, y: GPRegression(\n",
    "        X, y,\n",
    "        noise=torch.tensor(1e-4),\n",
    "        ### switched to Matern kernel\n",
    "        kernel=Matern32(\n",
    "            input_dim=1,\n",
    "            variance=torch.tensor(2, dtype=torch.float32, device=DEVICE),\n",
    "            lengthscale=torch.tensor(0.1, dtype=torch.float32, device=DEVICE)\n",
    "        ),\n",
    "    ).to(DEVICE),\n",
    "    acq=lcb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "bo.reset()\n",
    "\n",
    "for i in range(20):\n",
    "    x = bo.ask()\n",
    "    y = objective_many_minima_much_challenge(x)\n",
    "    \n",
    "    bo.tell(x, y)\n",
    "    \n",
    "    if (i + 1) % 5 == 0:\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plot_gp(bo.gp, X=np.array(bo.X), y=np.array(bo.y), objective=objective_many_minima_much_challenge)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Hyper-parameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "data = np.load('../../../share/HIGGS-small.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_all, y_all = data[:, 1:], data[:, 0]\n",
    "\n",
    "### casting labels to int\n",
    "y_all = np.where(y_all > 0.5, np.int(1), np.int(0))\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_all, y_all, test_size=0.25)\n",
    "\n",
    "print('Train     :', X_train.shape, y_train.shape)\n",
    "print('Validation:', X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Task 1\n",
    "\n",
    "Apply BO-GP to find the best number of trees and learning rate for `GradientBoostingClassifier`on the HIGGS dataset.\n",
    "\n",
    "The objective function consist of two term terms:\n",
    "- 1 - ROC AUC;\n",
    "- complexity penalty (number of trees).\n",
    "\n",
    "Don't forget to change the number of dimensions in `BayesianOptimization`: `BayesianOptimization(..., ndim=2)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def get_gb(x):\n",
    "    n_trees = int(100 * x[0] + 1)\n",
    "    log_learning_rate = x[1] * 6 - 3\n",
    "    learning_rate = np.exp(log_learning_rate)\n",
    "\n",
    "    return GradientBoostingClassifier(\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_trees, max_depth=3,\n",
    "        subsample=0.1, random_state=123\n",
    "    )\n",
    "\n",
    "def objective(x):\n",
    "    clf = get_gb(x)\n",
    "    \n",
    "    predictions = clf.fit(X_train, y_train).predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    error = 1 - roc_auc_score(y_val, predictions)\n",
    "    computational_penalty = 1e-1 * x[0]\n",
    "    \n",
    "    return error + computational_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ae23f97245eedf20227878f3604b1ec",
     "grade": false,
     "grade_id": "BO-HIGGS",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
   ],
   "source": [
    "bo = BayesianOptimization(\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "bo.reset()\n",
    "\n",
    "for _ in tqdm(range(20)):\n",
    "    x = bo.ask()\n",
    "    y = objective(x)\n",
    "    \n",
    "    bo.tell(x, y)\n",
    "\n",
    "### looking for the best guess with an exploitative acqusition function\n",
    "suggestions, values = minimize_acq(\n",
    "    x0=np.random.uniform(0, 1, size=(128, 2)),\n",
    "    gp=bo.gp,\n",
    "    n_iters=1024,\n",
    "    progress_bar=tqdm,\n",
    "    acq=exploitative\n",
    ")\n",
    "best = np.argmin(values)\n",
    "best_guess = suggestions[best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "clf = get_gb(best_guess)\n",
    "    \n",
    "predictions = clf.fit(X_train, y_train).predict_proba(X_val)[:, 1]\n",
    "\n",
    "auc = roc_auc_score(y_val, predictions)\n",
    "computational_penalty = 1e-1 * x[0]\n",
    "\n",
    "print('ROC AUC: %.3lf' % (auc, ))\n",
    "print('complexity: %.3lf' % (computational_penalty, ))\n",
    "\n",
    "assert True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}