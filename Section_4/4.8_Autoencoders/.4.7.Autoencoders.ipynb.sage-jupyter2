{"backend_state":"running","kernel":"python3","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":43900928},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"trust":true,"type":"settings"}
{"cell_type":"code","exec_count":0,"id":"5bf284","input":"","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":true,"grade_id":"5bf284","locked":true,"points":2,"schema_version":3,"solution":false,"task":false}},"pos":15,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"a31e56","input":"","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":true,"grade_id":"a31e56","locked":true,"points":2,"schema_version":3,"solution":false,"task":false}},"pos":11,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"c7da3a","input":"","pos":22,"type":"cell"}
{"cell_type":"code","exec_count":10,"id":"b5e979","input":"img = (img.permute((1,2,0))*255).detach().cpu().numpy().astype('uint8').squeeze()\nplt.imshow(img)","output":{"0":{"data":{"text/plain":"<matplotlib.image.AxesImage at 0x7ff43476d828>"},"exec_count":10,"output_type":"execute_result"},"1":{"data":{"image/png":"a14286807610801b395533ecbcd3ae4aca4dd26d","text/plain":"<Figure size 432x288 with 1 Axes>"},"exec_count":10,"output_type":"execute_result"}},"pos":16,"type":"cell"}
{"cell_type":"code","exec_count":2,"id":"ed892b","input":"import torch\nimport torch.utils.data\nfrom torch import nn, optim\nfrom torch.nn import functional as F\nfrom torchvision import datasets, transforms\nfrom torchvision.utils import save_image\nfrom torchvision.utils import make_grid\nfrom torch.utils.tensorboard import SummaryWriter\n\n\nseed=1\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice = \"cpu\"","pos":1,"type":"cell"}
{"cell_type":"code","exec_count":3,"id":"57b4d9","input":"from IPython.core.display import HTML\nfrom markdown import markdown\nimport os\n\nprint('Run the following command in terminal:')\nprint('tensorboard --logdir runs --bind_all')\n\nmarkdown_string = f\"Tensorboard URL: [https://mlhep.coresearch.club/{os.environ['COCALC_PROJECT_ID']}/server/6006/](https://mlhep.coresearch.club/{os.environ['COCALC_PROJECT_ID']}/server/6006/)\"\nwriter = SummaryWriter('runs/')\n\nHTML(\"<p>{}</p>\".format(markdown(markdown_string)))","output":{"0":{"name":"stdout","output_type":"stream","text":"Run the following command in terminal:\ntensorboard --logdir runs --bind_all\n"},"1":{"data":{"text/html":"<p><p>Tensorboard URL: <a href=\"https://mlhep.coresearch.club/46e46d61-bcb3-43dc-aa28-bd62f9267fb5/server/6006/\">https://mlhep.coresearch.club/46e46d61-bcb3-43dc-aa28-bd62f9267fb5/server/6006/</a></p></p>","text/plain":"<IPython.core.display.HTML object>"},"exec_count":3,"output_type":"execute_result"}},"pos":3,"type":"cell"}
{"cell_type":"code","exec_count":4,"id":"4fa2a5","input":"batch_size=128\nkwargs = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {}\n\nmnist_transforms = transforms.Compose([ \n    transforms.ToTensor(), # PIL Image -> Tensor\n#     transforms.Lambda(lambda x: x/255.),\n])\n\ntrain_loader = torch.utils.data.DataLoader(\n    datasets.MNIST('../../../share', train=True,\n                   transform=mnist_transforms),\n    batch_size=batch_size, shuffle=True, **kwargs)\n\ntest_loader = torch.utils.data.DataLoader(\n    datasets.MNIST('../../../share', train=False, transform=mnist_transforms),\n    batch_size=batch_size, shuffle=True, **kwargs)","pos":4,"type":"cell"}
{"cell_type":"code","exec_count":5,"id":"5673aa","input":"image, label = next(iter(train_loader))\nimage.shape\n%matplotlib inline\nimport matplotlib.pyplot as plt\nindx = 0\nplt.title(f'MNIST: {label[indx].item()}')\nplt.imshow(image[indx].squeeze(0))","output":{"0":{"data":{"text/plain":"<matplotlib.image.AxesImage at 0x7f42a96d5908>"},"exec_count":5,"output_type":"execute_result"},"1":{"data":{"image/png":"3c279291ed9be912a387f11e957ca9c2a833b47a","text/plain":"<Figure size 432x288 with 1 Axes>"},"exec_count":5,"output_type":"execute_result"}},"pos":5,"type":"cell"}
{"cell_type":"code","exec_count":5,"id":"6404ff","input":"class AE(nn.Module):\n    def __init__(self, hidden_size=20):\n        super(AE, self).__init__()\n        self.hidden_size = hidden_size\n\n        # Define self.encoder and self.decoder ()\n\n        self.encoder = nn.Sequential(\n            nn.Linear(784, 400),\n            nn.ReLU(),\n            nn.Linear(400, hidden_size)\n        )\n\n        self.decoder = nn.Sequential(\n            nn.Linear(hidden_size, 400),\n            nn.ReLU(),\n            nn.Linear(400, 784),\n            nn.Sigmoid()\n        )\n\n    def encode(self, x): return self.encoder(x.view(-1, 28*28))\n    def decode(self, z): return self.decoder(z).view(-1,28,28)\n    def forward(self, x): return self.decode(self.encode(x))\n    def sample(self, size):\n        return self.decode(torch.randn(size, self.hidden_size)).to(self.device)\n    @property\n    def device(self): return next(self.parameters()).device\n\n\nmodel = AE().to(device)\noptimizer = optim.Adam(model.parameters(), lr=1e-3)","metadata":{"nbgrader":{"cell_type":"code","checksum":"48d4531f5dd7aba719d8f2a87adc70d1","grade":false,"grade_id":"6404ff","locked":false,"schema_version":3,"solution":true,"task":false}},"pos":7,"type":"cell"}
{"cell_type":"code","exec_count":6,"id":"eba360","input":"for batch_idx, (data, _) in enumerate(train_loader):\n    data_recon = model(data.to(device))\n    assert data_recon.shape == torch.Size([128,28,28])\n    break","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":true,"grade_id":"eba360","locked":true,"points":1,"schema_version":3,"solution":false,"task":false}},"pos":8,"type":"cell"}
{"cell_type":"code","exec_count":7,"id":"0e68e0","input":"def recon_loss(recon_x, x):\n    # YOUR CODE HERE\n    MSE = F.mse_loss(recon_x.view(-1, 784), x.view(-1, 784), reduction='sum')\n    return MSE\n\n\nlog_interval=10\nepochs=30\n\ndef train(epoch):\n    model.train()\n    train_loss = 0\n    # YOUR CODE HERE\n    for batch_idx, (data, _) in enumerate(train_loader):\n        data = data.to(device)\n        optimizer.zero_grad()\n        recon_batch = model(data)\n        loss = recon_loss(recon_batch, data)\n        loss.backward()\n        train_loss += loss.item()\n        optimizer.step()\n\n    train_loss /= len(train_loader.dataset)\n    #writer.add_scalar('ae/train_loss', train_loss, epoch)\n\n    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss))\n\n\ndef test(epoch):\n    model.eval()\n    test_loss = 0\n    # YOUR CODE HERE\n    with torch.no_grad():\n        for i, (data, _) in enumerate(test_loader):\n            data = data.to(device)\n            recon_batch = model(data)\n            test_loss += recon_loss(recon_batch, data).item()\n    test_loss /= len(test_loader.dataset)\n    writer.add_scalar('ae/test_loss', test_loss)\n    return test_loss\n\nfor epoch in range(1, epochs + 1):\n    train(epoch)\n    test_loss = test(epoch)\n    with torch.no_grad():\n        sample_size=64\n        sample = model.sample(sample_size).cpu()\n        img = make_grid(sample.view(-1,1,28,28))\n        #writer.add_image('ae/test_image', img, epoch)","metadata":{"nbgrader":{"cell_type":"code","checksum":"37847e1d1fab8625cd63b3b3a600029c","grade":false,"grade_id":"0e68e0","locked":false,"schema_version":3,"solution":true,"task":false}},"output":{"0":{"name":"stdout","output_type":"stream","text":"====> Epoch: 1 Average loss: 27.7742\n"},"1":{"name":"stdout","output_type":"stream","text":"====> Epoch: 2 Average loss: 11.3964\n"},"10":{"name":"stdout","output_type":"stream","text":"====> Epoch: 11 Average loss: 6.6618\n"},"11":{"name":"stdout","output_type":"stream","text":"====> Epoch: 12 Average loss: 6.5311\n"},"12":{"name":"stdout","output_type":"stream","text":"====> Epoch: 13 Average loss: 6.4025\n"},"13":{"name":"stdout","output_type":"stream","text":"====> Epoch: 14 Average loss: 6.2952\n"},"14":{"name":"stdout","output_type":"stream","text":"====> Epoch: 15 Average loss: 6.1974\n"},"15":{"name":"stdout","output_type":"stream","text":"====> Epoch: 16 Average loss: 6.1139\n"},"16":{"name":"stdout","output_type":"stream","text":"====> Epoch: 17 Average loss: 6.0282\n"},"17":{"name":"stdout","output_type":"stream","text":"====> Epoch: 18 Average loss: 5.9659\n"},"18":{"name":"stdout","output_type":"stream","text":"====> Epoch: 19 Average loss: 5.8868\n"},"19":{"name":"stdout","output_type":"stream","text":"====> Epoch: 20 Average loss: 5.8337\n"},"2":{"name":"stdout","output_type":"stream","text":"====> Epoch: 3 Average loss: 9.6592\n"},"20":{"name":"stdout","output_type":"stream","text":"====> Epoch: 21 Average loss: 5.7778\n"},"21":{"name":"stdout","output_type":"stream","text":"====> Epoch: 22 Average loss: 5.7255\n"},"22":{"name":"stdout","output_type":"stream","text":"====> Epoch: 23 Average loss: 5.6727\n"},"23":{"name":"stdout","output_type":"stream","text":"====> Epoch: 24 Average loss: 5.6263\n"},"24":{"name":"stdout","output_type":"stream","text":"====> Epoch: 25 Average loss: 5.5902\n"},"25":{"name":"stdout","output_type":"stream","text":"====> Epoch: 26 Average loss: 5.5442\n"},"26":{"name":"stdout","output_type":"stream","text":"====> Epoch: 27 Average loss: 5.5117\n"},"27":{"name":"stdout","output_type":"stream","text":"====> Epoch: 28 Average loss: 5.4838\n"},"28":{"name":"stdout","output_type":"stream","text":"====> Epoch: 29 Average loss: 5.4404\n"},"29":{"name":"stdout","output_type":"stream","text":"====> Epoch: 30 Average loss: 5.4120\n"},"3":{"name":"stdout","output_type":"stream","text":"====> Epoch: 4 Average loss: 8.7898\n"},"4":{"name":"stdout","output_type":"stream","text":"====> Epoch: 5 Average loss: 8.2279\n"},"5":{"name":"stdout","output_type":"stream","text":"====> Epoch: 6 Average loss: 7.8070\n"},"6":{"name":"stdout","output_type":"stream","text":"====> Epoch: 7 Average loss: 7.4830\n"},"7":{"name":"stdout","output_type":"stream","text":"====> Epoch: 8 Average loss: 7.2249\n"},"8":{"name":"stdout","output_type":"stream","text":"====> Epoch: 9 Average loss: 7.0058\n"},"9":{"name":"stdout","output_type":"stream","text":"====> Epoch: 10 Average loss: 6.8255\n"}},"pos":10,"type":"cell"}
{"cell_type":"code","exec_count":7,"id":"bf98a3","input":"# Implement Sparse autoencoder with L1 regularization on each intermediate activation\n\nclass SparseAE(nn.Module):\n    def __init__(self, hidden_size=20):\n        super(SparseAE, self).__init__()\n        self.hidden_size = hidden_size\n\n        # Define self.encoder and self.decoder ()\n\n        # YOUR CODE HERE\n        self.encoder = nn.Sequential(\n            nn.Linear(784,400),\n            nn.ReLU(),\n            nn.Linear(400, hidden_size)\n        )\n\n        self.decoder = nn.Sequential(\n            nn.Linear(hidden_size,400),\n            nn.ReLU(),\n            nn.Linear(400, 784),\n            nn.Sigmoid()\n        )\n\n    def encode(self, x):\n        # YOUR CODE HERE\n        return self.encoder(x.view(-1, 28*28))\n    def decode(self, z): return self.decoder(z).view(-1,28,28)\n    def forward(self, x):\n        # YOUR CODE HERE\n        reg_loss = 0 # accumulate L1\n        values = x.view(-1, 28*28)\n        for l in self.encoder.children():\n            values = F.relu(l(values))\n            reg_loss += torch.mean(torch.abs(values))\n        return self.decode(values), reg_loss\n    def sample(self, size):\n        # YOUR CODE HERE\n        return self.decode(torch.randn(size, self.hidden_size).to(self.device))\n    @property\n    def device(self): return next(self.parameters()).device\n\nmodel = SparseAE().to(device)\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\n\ndef recon_loss(recon_x, x):\n    # YOUR CODE HERE\n    MSE = F.mse_loss(recon_x.view(-1, 784), x.view(-1, 784), reduction='sum')\n    return MSE\n\n\n# log_interval=10\nepochs=30\nvar = 1e-2\n\ndef train(epoch):\n    model.train()\n    train_loss, train_loss_reg = 0, 0\n    # YOUR CODE HERE\n    for batch_idx, (data, _) in enumerate(train_loader):\n        data = data.to(device)\n        optimizer.zero_grad()\n        recon_batch, reg_loss = model(data + var * torch.randn_like(data))\n        loss = recon_loss(recon_batch, data)\n        loss.backward(retain_graph=True)\n        reg_loss.backward()\n        train_loss += loss.item()\n        train_loss_reg += reg_loss.item()\n        optimizer.step()\n\n    train_loss /= len(train_loader.dataset)\n    train_loss_reg /= len(train_loader.dataset)\n    #writer.add_scalar('dae/train_loss', train_loss)\n    #writer.add_scalar('dae/train_loss_reg', train_loss_reg)\n\n    print('====> Epoch: {} Average loss: {:.4f} Reg loss: {:.4f}'.format(epoch, train_loss, train_loss_reg))\n\n\ndef test(epoch):\n    model.eval()\n    test_loss, test_loss_reg = 0, 0\n    # YOUR CODE HERE\n    with torch.no_grad():\n        for i, (data, _) in enumerate(test_loader):\n            data = data.to(device)\n            recon_batch, reg_loss = model(data)\n            test_loss += recon_loss(recon_batch, data).item()\n            test_loss_reg += reg_loss.item()\n    test_loss /= len(test_loader.dataset)\n    test_loss_reg /= len(test_loader.dataset)\n    #writer.add_scalar('dae/test_loss', test_loss)\n    return test_loss, test_loss_reg\n\nfor epoch in range(1, epochs + 1):\n    train(epoch)\n    test_loss, test_loss_reg = test(epoch)\n    with torch.no_grad():\n        sample_size=64\n        sample = model.sample(sample_size).cpu()\n        img = make_grid(sample.view(-1,1,28,28))\n        #writer.add_image('sae/test_image', img, epoch)","metadata":{"nbgrader":{"checksum":"acc02b273a7f953c0542b8925bf48200","grade":false,"grade_id":"bf98a3","locked":false,"schema_version":3,"solution":true,"task":false}},"output":{"0":{"name":"stdout","output_type":"stream","text":"====> Epoch: 1 Average loss: 32.8180 Reg loss: 0.0391\n"},"1":{"name":"stdout","output_type":"stream","text":"====> Epoch: 2 Average loss: 19.0362 Reg loss: 0.0459\n"},"10":{"name":"stdout","output_type":"stream","text":"====> Epoch: 11 Average loss: 13.4541 Reg loss: 0.0509\n"},"11":{"name":"stdout","output_type":"stream","text":"====> Epoch: 12 Average loss: 13.2787 Reg loss: 0.0505\n"},"12":{"name":"stdout","output_type":"stream","text":"====> Epoch: 13 Average loss: 13.1210 Reg loss: 0.0504\n"},"13":{"name":"stdout","output_type":"stream","text":"====> Epoch: 14 Average loss: 12.9921 Reg loss: 0.0499\n"},"14":{"name":"stdout","output_type":"stream","text":"====> Epoch: 15 Average loss: 12.8659 Reg loss: 0.0496\n"},"15":{"name":"stdout","output_type":"stream","text":"====> Epoch: 16 Average loss: 12.7525 Reg loss: 0.0493\n"},"16":{"name":"stdout","output_type":"stream","text":"====> Epoch: 17 Average loss: 12.6480 Reg loss: 0.0490\n"},"17":{"name":"stdout","output_type":"stream","text":"====> Epoch: 18 Average loss: 12.5525 Reg loss: 0.0486\n"},"18":{"name":"stdout","output_type":"stream","text":"====> Epoch: 19 Average loss: 12.4565 Reg loss: 0.0484\n"},"19":{"name":"stdout","output_type":"stream","text":"====> Epoch: 20 Average loss: 12.3742 Reg loss: 0.0479\n"},"2":{"name":"stdout","output_type":"stream","text":"====> Epoch: 3 Average loss: 17.1982 Reg loss: 0.0488\n"},"20":{"name":"stdout","output_type":"stream","text":"====> Epoch: 21 Average loss: 12.2904 Reg loss: 0.0478\n"},"21":{"name":"stdout","output_type":"stream","text":"====> Epoch: 22 Average loss: 12.2236 Reg loss: 0.0475\n"},"22":{"name":"stdout","output_type":"stream","text":"====> Epoch: 23 Average loss: 12.1433 Reg loss: 0.0471\n"},"23":{"name":"stdout","output_type":"stream","text":"====> Epoch: 24 Average loss: 12.0763 Reg loss: 0.0469\n"},"24":{"name":"stdout","output_type":"stream","text":"====> Epoch: 25 Average loss: 12.0098 Reg loss: 0.0466\n"},"25":{"name":"stdout","output_type":"stream","text":"====> Epoch: 26 Average loss: 11.9492 Reg loss: 0.0463\n"},"26":{"name":"stdout","output_type":"stream","text":"====> Epoch: 27 Average loss: 11.8894 Reg loss: 0.0461\n"},"27":{"name":"stdout","output_type":"stream","text":"====> Epoch: 28 Average loss: 11.8299 Reg loss: 0.0459\n"},"28":{"name":"stdout","output_type":"stream","text":"====> Epoch: 29 Average loss: 11.7903 Reg loss: 0.0456\n"},"29":{"name":"stdout","output_type":"stream","text":"====> Epoch: 30 Average loss: 11.7359 Reg loss: 0.0452\n"},"3":{"name":"stdout","output_type":"stream","text":"====> Epoch: 4 Average loss: 16.1509 Reg loss: 0.0506\n"},"4":{"name":"stdout","output_type":"stream","text":"====> Epoch: 5 Average loss: 15.4296 Reg loss: 0.0516\n"},"5":{"name":"stdout","output_type":"stream","text":"====> Epoch: 6 Average loss: 14.8948 Reg loss: 0.0520\n"},"6":{"name":"stdout","output_type":"stream","text":"====> Epoch: 7 Average loss: 14.4929 Reg loss: 0.0519\n"},"7":{"name":"stdout","output_type":"stream","text":"====> Epoch: 8 Average loss: 14.1487 Reg loss: 0.0518\n"},"8":{"name":"stdout","output_type":"stream","text":"====> Epoch: 9 Average loss: 13.8755 Reg loss: 0.0516\n"},"9":{"name":"stdout","output_type":"stream","text":"====> Epoch: 10 Average loss: 13.6490 Reg loss: 0.0512\n"}},"pos":18,"type":"cell"}
{"cell_type":"code","exec_count":8,"id":"927b3c","input":"### BEGIN HIDDEN TESTS\n# students will NOT see these extra tests\nassert test_loss < 12\nassert test_loss_reg < 1\n### END HIDDEN TESTS","pos":19,"type":"cell"}
{"cell_type":"code","exec_count":8,"id":"ca9472","input":"img = (img.permute((1,2,0))*255).detach().cpu().numpy().astype('uint8').squeeze()\nplt.imshow(img)","output":{"0":{"data":{"text/plain":"<matplotlib.image.AxesImage at 0x7ff434708eb8>"},"exec_count":8,"output_type":"execute_result"},"1":{"data":{"image/png":"5b3a5aaf7f3909cecb427526d128731ae3a70301","text/plain":"<Figure size 432x288 with 1 Axes>"},"exec_count":8,"output_type":"execute_result"}},"pos":12,"type":"cell"}
{"cell_type":"code","exec_count":9,"id":"878673","input":"img = (img.permute((1,2,0))*255).detach().cpu().numpy().astype('uint8').squeeze()\nplt.imshow(img)","output":{"0":{"data":{"text/plain":"<matplotlib.image.AxesImage at 0x7f42a957f5f8>"},"exec_count":9,"output_type":"execute_result"},"1":{"data":{"image/png":"03cbb4aa383dd9f6bbdf8a3da93163d0a0a36af3","text/plain":"<Figure size 432x288 with 1 Axes>"},"exec_count":9,"output_type":"execute_result"}},"pos":20,"type":"cell"}
{"cell_type":"code","exec_count":9,"id":"e74702","input":"model = AE().to(device)\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\n\ndef recon_loss(recon_x, x):\n    # YOUR CODE HERE\n    MSE = F.mse_loss(recon_x.view(-1, 784), x.view(-1, 784), reduction='sum')\n    return MSE\n\n\n# log_interval=10\nepochs=30\n\ndef train(epoch,var=1e-2):\n    model.train()\n    train_loss = 0\n    # Add noise to image in training stage with \"var\" variance\n    # YOUR CODE HERE\n    for batch_idx, (data, _) in enumerate(train_loader):\n        data = data.to(device)\n        optimizer.zero_grad()\n        recon_batch = model(data + var * torch.randn_like(data))\n        loss = recon_loss(recon_batch, data)\n        loss.backward()\n        train_loss += loss.item()\n        optimizer.step()\n\n    train_loss /= len(train_loader.dataset)\n    #writer.add_scalar('dae/train_loss', train_loss)\n\n    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss))\n\n\n\ndef test(epoch):\n    model.eval()\n    test_loss = 0\n    # YOUR CODE HERE\n    with torch.no_grad():\n        for i, (data, _) in enumerate(test_loader):\n            data = data.to(device)\n            recon_batch = model(data)\n            test_loss += recon_loss(recon_batch, data).item()\n    test_loss /= len(test_loader.dataset)\n    writer.add_scalar('dae/test_loss', test_loss)\n    return test_loss\n\nfor epoch in range(1, epochs + 1):\n    train(epoch)\n    test_loss = test(epoch)\n    with torch.no_grad():\n        sample_size=64\n        sample = model.sample(sample_size).cpu()\n        img = make_grid(sample.view(-1,1,28,28))\n        #writer.add_image('dae/test_image', img, epoch)\n","metadata":{"nbgrader":{"checksum":"8c20f7cd9ac00e7e8e0562118e1ca658","grade":false,"grade_id":"e74702","locked":false,"schema_version":3,"solution":true,"task":false}},"output":{"0":{"name":"stdout","output_type":"stream","text":"====> Epoch: 1 Average loss: 27.9184\n"},"1":{"name":"stdout","output_type":"stream","text":"====> Epoch: 2 Average loss: 11.3667\n"},"10":{"name":"stdout","output_type":"stream","text":"====> Epoch: 11 Average loss: 6.5703\n"},"11":{"name":"stdout","output_type":"stream","text":"====> Epoch: 12 Average loss: 6.4339\n"},"12":{"name":"stdout","output_type":"stream","text":"====> Epoch: 13 Average loss: 6.3194\n"},"13":{"name":"stdout","output_type":"stream","text":"====> Epoch: 14 Average loss: 6.2174\n"},"14":{"name":"stdout","output_type":"stream","text":"====> Epoch: 15 Average loss: 6.1291\n"},"15":{"name":"stdout","output_type":"stream","text":"====> Epoch: 16 Average loss: 6.0463\n"},"16":{"name":"stdout","output_type":"stream","text":"====> Epoch: 17 Average loss: 5.9778\n"},"17":{"name":"stdout","output_type":"stream","text":"====> Epoch: 18 Average loss: 5.9036\n"},"18":{"name":"stdout","output_type":"stream","text":"====> Epoch: 19 Average loss: 5.8431\n"},"19":{"name":"stdout","output_type":"stream","text":"====> Epoch: 20 Average loss: 5.7888\n"},"2":{"name":"stdout","output_type":"stream","text":"====> Epoch: 3 Average loss: 9.6269\n"},"20":{"name":"stdout","output_type":"stream","text":"====> Epoch: 21 Average loss: 5.7426\n"},"21":{"name":"stdout","output_type":"stream","text":"====> Epoch: 22 Average loss: 5.6890\n"},"22":{"name":"stdout","output_type":"stream","text":"====> Epoch: 23 Average loss: 5.6438\n"},"23":{"name":"stdout","output_type":"stream","text":"====> Epoch: 24 Average loss: 5.5986\n"},"24":{"name":"stdout","output_type":"stream","text":"====> Epoch: 25 Average loss: 5.5658\n"},"25":{"name":"stdout","output_type":"stream","text":"====> Epoch: 26 Average loss: 5.5302\n"},"26":{"name":"stdout","output_type":"stream","text":"====> Epoch: 27 Average loss: 5.4951\n"},"27":{"name":"stdout","output_type":"stream","text":"====> Epoch: 28 Average loss: 5.4589\n"},"28":{"name":"stdout","output_type":"stream","text":"====> Epoch: 29 Average loss: 5.4327\n"},"29":{"name":"stdout","output_type":"stream","text":"====> Epoch: 30 Average loss: 5.3986\n"},"3":{"name":"stdout","output_type":"stream","text":"====> Epoch: 4 Average loss: 8.7570\n"},"4":{"name":"stdout","output_type":"stream","text":"====> Epoch: 5 Average loss: 8.1695\n"},"5":{"name":"stdout","output_type":"stream","text":"====> Epoch: 6 Average loss: 7.7409\n"},"6":{"name":"stdout","output_type":"stream","text":"====> Epoch: 7 Average loss: 7.4007\n"},"7":{"name":"stdout","output_type":"stream","text":"====> Epoch: 8 Average loss: 7.1332\n"},"8":{"name":"stdout","output_type":"stream","text":"====> Epoch: 9 Average loss: 6.9158\n"},"9":{"name":"stdout","output_type":"stream","text":"====> Epoch: 10 Average loss: 6.7230\n"}},"pos":14,"type":"cell"}
{"cell_type":"markdown","id":"3c7faf","input":"# Sparse autoencoder","pos":17,"type":"cell"}
{"cell_type":"markdown","id":"66758a","input":"## Autoencoder model\n![](http://bjlkeng.github.io/images/autoencoder_structure.png)","pos":6,"type":"cell"}
{"cell_type":"markdown","id":"679530","input":"# Denoising autoencoder","pos":13,"type":"cell"}
{"cell_type":"markdown","id":"98e44c","input":"## Train model","pos":9,"type":"cell"}
{"cell_type":"markdown","id":"b7f4b8","input":"# Links\n\n[Simple explanation of AE](http://bjlkeng.github.io/posts/autoregressive-autoencoders/)\n\n[Sparse autoencoder](https://debuggercafe.com/sparse-autoencoders-using-l1-regularization-with-pytorch/)\n\n[Denoising autoencoder](https://towardsdatascience.com/denoising-autoencoders-explained-dbb82467fc2)","pos":21,"type":"cell"}
{"cell_type":"markdown","id":"decb7e","input":"# Dataset\nMNIST dataset will be used","pos":2,"type":"cell"}
{"cell_type":"markdown","id":"fe4af0","input":"# Autoencoders","pos":0,"type":"cell"}
{"id":0,"time":1596644917793,"type":"user"}
{"last_load":1596648506016,"type":"file"}